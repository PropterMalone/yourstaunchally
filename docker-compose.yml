services:
  ollama:
    image: ollama/ollama:latest
    restart: unless-stopped
    volumes:
      - ollama-data:/root/.ollama
    # CPU-only â€” no GPU runtime needed

  engine:
    build: .
    restart: unless-stopped
    env_file: .env
    environment:
      - DB_PATH=/data/yourstaunchally.db
      - PYTHON_PATH=/app/.venv/bin/python3
      - OLLAMA_URL=http://ollama:11434
    volumes:
      - ./data:/data
    depends_on:
      - ollama
    networks:
      - default
      - propter-net

  feed:
    build: .
    restart: unless-stopped
    command: ["node", "packages/feed/dist/index.js"]
    environment:
      - DB_PATH=/data/yourstaunchally.db
      - FEED_PORT=3001
      - FEED_HOSTNAME=${FEED_HOSTNAME:-localhost}
      - FEED_PUBLISHER_DID=${FEED_PUBLISHER_DID:-did:web:localhost}
    volumes:
      - ./data:/data:ro
    ports:
      - "3005:3001"
    depends_on:
      - engine

volumes:
  ollama-data:

networks:
  propter-net:
    name: propter-net
    external: true
